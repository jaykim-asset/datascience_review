{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 활용한 Market Data Cutting (미완성)\n",
    "- 아직 내가 원하는데로 Fully Cutting을 못함.\n",
    "- code가 돌아가는데, 너무 오래 걸림 \n",
    "    - Why? \n",
    "        - 1) pd.read_csv에서 파일 (81.20 MB)을 읽다 보니, 여기에서 많이 잡아먹음.\n",
    "            - 내 컴퓨터 기준 (around 900ms)\n",
    "        - 2) Product Code를 찾기 위해서, 다시 A0016 & 001 & BMA 있는 Row를 찾다보니, 또 여기서 시간 잡아먹음.\n",
    "            - 내 컴퓨터 기준 (around 500ms)\n",
    "        - 3) Product Code를 기준으로 'A3'와 'G7' Packets만 sorting 하는데 시간이 많이 걸림.\n",
    "            - 내 컴퓨터 기준 (around 500ms)\n",
    "- Overall Latency: Approximately 2 seconds\n",
    "    - 굉장히 느리며, 이유는 1),2),3) 모두 row를 read해야 하기에 오래 걸리는것 같음\n",
    "    \n",
    "- 개선방향\n",
    "    - 사실, pd.read_csv에서 around 900ms 걸린다면, 밑에 만든 Readline을 활용한 MarketData Cutting을 사용하는게 더 나음\n",
    "    - readline의 경우에는 모든 작업이 끝나는데 400ms 걸림.... \n",
    "    - pandas를 활용하면, 훨씬더 빠르다고 들었지만, 그건 아닌것 같음. 파일의 Size, data 형태를 고려해서 선택해야 할 듯 함.|\n",
    "    \n",
    "- 갑자기 든 생각 => Value 값들을 String으로 변환 해야 함!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('D:\\\\Sise_test\\\\sise2local.ALL_CMDT.0213', 'r', encoding='ISO-8859-1', header=None, names=None, index_col=None)\n",
    "\n",
    "df[0] = df.iloc[:,0]\n",
    "\n",
    "KM10_ID = df[(df[0].str.contains('A0016')) & (df[0].str.contains('001')) &\n",
    "             (df[0].str.contains('BMA'))].iloc[0][0][35:47] # 장운영TS의 국채10년 최근월물\n",
    "\n",
    "# KM3_id = df[(df[0].str.contains('A0016')) & (df[0].str.contains('001')) & (df[0].str.contains('BM3'))].iloc[0][0][35:47] # 국채 3년\n",
    "# USD_id = df[(df[0].str.contains('A0016')) & (df[0].str.contains('001')) & (df[0].str.contains('USD'))].iloc[0][0][35:47] # USD선물\n",
    "\n",
    "# print(KM10_ID)\n",
    "\n",
    "K10_A3_G7 = df[(df[0].str.contains(KM10_ID)) & ((df[0].str.contains('A3')) | (df[0].str.contains('G7')))] # A3 packet 와 G7 packet grap\n",
    "\n",
    "K10_A3_G7.to_csv('D:\\\\Sise_test\\\\K10_A3_G7.csv', index=False, header=None) # 파일 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readline 활용한 Market Data Cutting (미완성)\n",
    "- Readline을 바탕으로 최근에 배운 Pandas를 활용해서 Pandas를 사용했지만, 성능면에서는 Readline이 훨씬 더 빠름.\n",
    "- 하지만, Pandas는 익숙해지면, readline같은 code를 만드는 것 보다, pandas를 활용해서 하는것이 더 빠른 code를 짜게 할 것 같음.\n",
    "- Readline에 추가해야 할 것\n",
    "    - 1) File이 csv로 저장이 되면, sheetname이 file create 할 때, 파일명으로 저장됨.\n",
    "        - 아마도, csv 파일을 다시 xlsm으로 변환 할 때, sheetname지정하는 기능이 있는걸 보았음. 그걸 활용해서 sheetname을 sheetname1로 변경해야, 지금 만들어져 있는 프로그램이랑 smooth하게 연동 가능 할 듯 함.\n",
    "    - 2) 파일명: Product Name 및 날짜가 찍히게 수정하기. (Ex.KR4167N30003_0219) \n",
    "    - 3) Python folder names in the directory 기능 가능한지 알아보기 \n",
    "        - Why?\n",
    "            - 과거 3년치 Data가 있다면, 파일명을 하루하루 바꿔서 하는것은 비효율 적이니, Directory의 filename을 list형태로 변환 후, for 문에 file name을 list로 집어 넣고, 돌리면, 자동으로 돌아가면서 3년치 데이터를 변환 할 수 있을 것 같다.\n",
    "\n",
    "\n",
    "- 갑자기 든 생각 => Value 값들을 String으로 변환 해야 함!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KR4167N30003\n",
      "Wall time: 1.95 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "f = open('D:\\\\Sise_test\\\\sise2local.ALL_CMDT.0213', 'r', encoding='ISO-8859-1')\n",
    "f_1 = open('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv', 'a', encoding='ISO-8859-1')\n",
    "f_1.write('time,cur_price,exe_quantity,short_lvl1_price,short_lvl1_quantity,long_lvl1_price,long_lvl1_quantity,long_or_short,All_short_quantity,All_long_quantity\\n')\n",
    "\n",
    "KTB_productID = ' '\n",
    "\n",
    "while KTB_productID:\n",
    "    line = f.readline()\n",
    "    if (line[17:22] == 'A0016') and (line[425:428] == 'BMA') and (line[471:474] == '001') == True: ## BMA: 10년 국채 Code\n",
    "        KTB_productID = line[35:47]\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    line = f.readline()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "    if (line[17:19] == 'A3') and (line.count(KTB_productID) == 1):\n",
    "        line = line[0:17] + ',' + line[40:48] + ',' + line[48:54] + ',,,,,' + line[152] + '\\n'\n",
    "        f_1.write(line)\n",
    "\n",
    "    elif line[17:19] == 'G7' and line.count(KTB_productID):\n",
    "        line = line[0:17] + ',' + line[40:48] + ',' + line[48:54] + ',' + line[243:251] + ',' + line[-135:-129] + ',' + line[161:169] + ',' + line[169:175] + ',' + line[152] + ',' + line[-151:-144] + ',' + line[153:160] + '\\n'\n",
    "        f_1.write(line)\n",
    "\n",
    "print(KTB_productID)\n",
    "\n",
    "f_1.close()\n",
    "f.close()\n",
    "\n",
    "data = pd.read_csv('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv') # pd.read 대신에 , read기능이나 다른기능이 더 효율적일순 없을까?\n",
    "data = data.ix[1:]     # row(1) 삭제 하기 위함 - Auction Period 체결량이지만, 지금 활용하고 싶지는 않음\n",
    "data.to_csv('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "f = open('D:\\\\Sise_test\\\\sise2local.ALL_CMDT.0213', 'r', encoding='ISO-8859-1')\n",
    "f_1 = open('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv', 'a', encoding='ISO-8859-1')\n",
    "f_1.write('time,cur_price,exe_quantity,short_lvl1_price,short_lvl1_quantity,long_lvl1_price,long_lvl1_quantity,long_or_short,All_short_quantity,All_long_quantity\\n')\n",
    "\n",
    "KTB_productID = ' '\n",
    "\n",
    "while KTB_productID:\n",
    "    line = f.readline()\n",
    "    if (line[17:22] == 'A0016') and (line[425:428] == 'BMA') and (line[471:474] == '001') == True: ## BMA: 10년 국채 Code\n",
    "        KTB_productID = line[35:47]\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    line = f.readline()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "    if (line[17:19] == 'A3') and (line.count(KTB_productID) == 1):\n",
    "        line = line[0:17] + ',' + line[40:48] + ',' + line[48:54] + ',,,,,' + line[152] + '\\n'\n",
    "        f_1.write(line)\n",
    "\n",
    "    elif line[17:19] == 'G7' and line.count(KTB_productID):\n",
    "        line = line[0:17] + ',' + line[40:48] + ',' + line[48:54] + ',' + line[243:251] + ',' + line[-135:-129] + ',' + line[161:169] + ',' + line[169:175] + ',' + line[152] + ',' + line[-151:-144] + ',' + line[153:160] + '\\n'\n",
    "        f_1.write(line)\n",
    "\n",
    "print(KTB_productID)\n",
    "\n",
    "f_1.close()\n",
    "f.close()\n",
    "\n",
    "data = pd.read_csv('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv') # pd.read 대신에 , read기능이나 다른기능이 더 효율적일순 없을까?\n",
    "data = data.ix[1:]     # row(1) 삭제 하기 위함 - Auction Period 체결량이지만, 지금 활용하고 싶지는 않음\n",
    "data.to_csv('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-0f91984df039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\\\Sise_test\\\\K10_A3_G7_readline.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'long_lvl1_quantity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   4002\u001b[0m         \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4003\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[1;32m-> 4004\u001b[1;33m                                      **kwargs)\n\u001b[0m\u001b[0;32m   4005\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   3460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3462\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3328\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3329\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3330\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[1;32m--> 544\u001b[1;33m                             **kwargs)\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"datetime64\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"timedelta64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src/util.pxd\u001b[0m in \u001b[0;36mutil.set_value_at_unsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'type'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv')\n",
    "df.loc[:, 'long_lvl1_quantity'].fillna(float(N)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KR4167N30003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# f = open('D:\\\\Sise_test\\\\sise2local.ALL_CMDT.0213', 'r', encoding='ISO-8859-1')\n",
    "# f_1 = open('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv', 'a', encoding='ISO-8859-1')\n",
    "# f_1.write('time,cur_price,exe_quantity,short_lvl1_price,short_lvl1_quantity,long_lvl1_price,long_lvl1_quantity,long_or_short,All_short_quantity,All_long_quantity\\n')\n",
    "\n",
    "# KTB_productID = ' '\n",
    "\n",
    "# while KTB_productID:\n",
    "#     line = f.readline()\n",
    "#     if (line[17:22] == 'A0016') and (line[425:428] == 'BMA') and (line[471:474] == '001') == True: ## BMA: 10년 국채 Code\n",
    "#         KTB_productID = line[35:47]\n",
    "#         break\n",
    "\n",
    "# while True:\n",
    "#     line = f.readline()\n",
    "\n",
    "#     if not line:\n",
    "#         break\n",
    "\n",
    "#     if (line[17:19] == 'A3') and (line.count(KTB_productID) == 1):\n",
    "#         line = line[0:17] + ',' + line[40:48] + ',' + line[48:54] + ',,,,,' + line[152] + '\\n'\n",
    "#         f_1.write(line)\n",
    "\n",
    "#     elif line[17:19] == 'G7' and line.count(KTB_productID):\n",
    "#         line = line[0:17] + ',' + line[40:48] + ',' + line[48:54] + ',' + line[243:251] + ',' + line[-135:-129] + ',' + line[161:169] + ',' + line[169:175] + ',' + line[152] + ',' + line[-151:-144] + ',' + line[153:160] + '\\n'\n",
    "#         f_1.write(line)\n",
    "\n",
    "# print(KTB_productID)\n",
    "\n",
    "# f_1.close()\n",
    "# f.close()\n",
    "\n",
    "# # data = pd.read_csv('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv')\n",
    "\n",
    "\n",
    "# # time\tcur_price\texe_quantity\tshort_lvl1_price\tshort_lvl1_quantity\tlong_lvl1_price\tlong_lvl1_quantity\tlong_or_short\tAll_short_quantity\tAll_long_quantity\n",
    "\n",
    "# data = pd.read_csv('D:\\\\Sise_test\\\\K10_A3_G7_readline.csv', converters={'cur_price':int})\n",
    "# # pd.to_numeric(s, downcast='float')\n",
    "\n",
    "# # pd.to_numeric(data.iloc[:,1], downcast='integer', errors='coerce').to_csv('D:\\\\Sise_test\\\\test.csv', index=False)\n",
    "# data.iloc[:,1].to_csv('D:\\\\Sise_test\\\\test.csv', index=False, float_format=True)\n",
    "# # df=pandas.read_csv(\"C:/Folder/Data.csv\",converters={\"Price\":int})\n",
    "# # print(data.iloc[:,1].astype(int)) # cur_price int\n",
    "# # print(data.iloc[:,2].fillna(value=0).astype('int')) # exe_quantity\n",
    "\n",
    "\n",
    "# # pd.read 대신에 , read기능이나 다른기능이 더 효율적일순 없을까?\n",
    "# data = data.ix[1:]     # row(1) 삭제 하기 위함 - Auction Period 체결량이지만, 지금 활용하고 싶지는 않음\n",
    "\n",
    "# # print(data.iloc[:,7].fillna(value=0).astype('int'))\n",
    "# # numeric = data.iloc[:,7].fillna('0')# pd.to_numeric(s, errors='ignore')\n",
    "# # numeric.convert_objects(convert_numeric=True).astype(int)\n",
    "# # print((numeric))\n",
    "# # df['ColumnName'] = df['ColumnName'].convert_objects(convert_numeric=True) str -> 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
